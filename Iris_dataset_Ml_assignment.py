{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPStJLjIOwNGynFGTmnEqB9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"Kf6UVZ02qfgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqJQrVfkmJ2R","executionInfo":{"status":"ok","timestamp":1724741430164,"user_tz":-330,"elapsed":5898,"user":{"displayName":"Abhii Vishwa.","userId":"11665901673592639552"}},"outputId":"6053991a-f980-4f4f-bed6-57e397f37932"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 5 rows:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                5.1               3.5                1.4               0.2\n","1                4.9               3.0                1.4               0.2\n","2                4.7               3.2                1.3               0.2\n","3                4.6               3.1                1.5               0.2\n","4                5.0               3.6                1.4               0.2\n","\n","Dataset shape:\n","(150, 4)\n","\n","Summary statistics:\n","       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n","count         150.000000        150.000000         150.000000   \n","mean            5.843333          3.057333           3.758000   \n","std             0.828066          0.435866           1.765298   \n","min             4.300000          2.000000           1.000000   \n","25%             5.100000          2.800000           1.600000   \n","50%             5.800000          3.000000           4.350000   \n","75%             6.400000          3.300000           5.100000   \n","max             7.900000          4.400000           6.900000   \n","\n","       petal width (cm)  \n","count        150.000000  \n","mean           1.199333  \n","std            0.762238  \n","min            0.100000  \n","25%            0.300000  \n","50%            1.300000  \n","75%            1.800000  \n","max            2.500000  \n","\n","Number of samples in training set: 120\n","Number of samples in testing set: 30\n"]}],"source":["import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","\n","# Convert to DataFrame for easier exploration\n","iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","\n","# Display the first five rows\n","print(\"First 5 rows:\")\n","print(iris_df.head())\n","\n","# Display the dataset shape\n","print(\"\\nDataset shape:\")\n","print(iris_df.shape)\n","\n","# Display summary statistics\n","print(\"\\nSummary statistics:\")\n","print(iris_df.describe())\n","\n","\n","# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n","\n","# Print the number of samples in the training and testing sets\n","print(\"\\nNumber of samples in training set:\", len(X_train))\n","print(\"Number of samples in testing set:\", len(X_test))"]},{"cell_type":"markdown","source":[],"metadata":{"id":"SiSJ_w7Lqbej"}}]}
